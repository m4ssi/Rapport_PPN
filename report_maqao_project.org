#+TITLE: MAQAO REPORT
#+AUTHOR: Akli HAMITOUCHE - Amar HENNI - Amayas OUAKED - Imane KHELOUAT - Salem Aghiles BRAI

*  Introduction



** Présentation de l'outil MAQAO
** SIMD/Vectorisation
** Flags d'optimisation des compilateurs

|-------------------------+-----------+-----------------------------------------------------------------------|
| Flags                   | Valeurs   | Description                                                           |
|-------------------------+-----------+-----------------------------------------------------------------------|
| -g                      |           | produit les informations de debug dans le format de l'OS              |
|                         |           | permet d'avoir le lien entre le binaire et le source                  |
| -fnp-omit-frame-pointer |           | permet d'avoir les callchains avec les options par défaut du profiler |
| -O2                     |           |                                                                       |
| -O3                     |           |                                                                       |
| -Ofast                  |           |                                                                       |
| -funroll-loops          |           |                                                                       |
| -fassociative-math      |           |                                                                       |
| -ftree-vectorize        |           |                                                                       |
| -floop-unroll-and-jam   |           |                                                                       |
| -march=                 | native    |                                                                       |
|                         | core-avx2 |                                                                       |
|                         | x86-64    |                                                                       |
| -mtune=                 | native    |                                                                       |
|-------------------------+-----------+-----------------------------------------------------------------------|

*  ABC-MAQAO sur un cas simple : *dotprod*

Afin de réaliser ce projet, une étape clé était de comprendre et d'apprendre à utiliser *MAQAO*. Pour cela, nous avons cherché à optimiser un
benchmark deja vu en cours : le *dotprod*. L'idée était de faire le travail d'optimisation un maximum de fois depuis la version de base afin 
d'identifier les informations récurrentes et exploitable qui nous étaient produites. Une fois ces sections identifiées, une chaine de production
d'un binaire (processus d'optimisation) a été mise en place et expliqué dans cette section.

Les résultats obtenus lors de cette analyse peuvent être retrouvés sur ce dépôt : [[Dépot contenant les RUNS et les sources du dotprod][https://github.com/m4ssi/Dotprod]]

** Chaine de production d'un binaire : 

La chaine de production mise en oeuvre, schématisée par la figure 1, se déroule telle que :

1) Compilation sans options de compilation
2) Analyse du binaire obtenu 
3) Recompilation du programme avec les options suggérés et avec O2, O3 ou Ofast (généralement Ofast - passage en 7)
4) Analyse des trois binaire obtenu
5) Si les suggestions faites sont differentes pour les trois : retour en 3
6) Sinon : choix du meilleur flags (compromis entre le temps d'exécution et taille du binaire) puis 7
7) Application des recommandations et analyse jusqu'a trouver une limite

   #+CAPTION: Processur iteratif d'optimisation à l'aide de MAQAO
   #+NAME: fig: optimization_process
   #+ATTR_HTML: :width 600px
   [[./img/inter_process.png]]

** Code source

*** Makefile

Comme on peut le voir sur le Makefile suivant, notre programme est compilé sans aucune optimisation
afin de commencer notre analyse depuis le début.

#+BEGIN_SRC make
all: 00.dotprod

00.dotprod:
	gcc -Wall -g -fno-omit-frame-pointer -O0 -o $@ $@.c
	
#+END_SRC

*** *dotprod.c*

Une particularité du dotprod ci-après présenté est qu'il nous permet de fixer une taille de vecteur en Bytes
et de boucler sur la fonciton principale afin de pouvoir jouer sur le temps d'exécution de notre programme d'une part
et ainsi mieux voir la performance gagné.

#+BEGIN_SRC c
double dotprod(double *restrict a, double *restrict b, unsigned long long n)	{
	double d = 0.0;
	for ( unsigned long long i = 0; i < n; i++)
		d += a[i] * b[i];
	return d;	
}

void fill_vector (double *restrict vect, unsigned long long n)	{
	for (unsigned long long i = 0; i < n; i++)
		vect[i] = 1;
}

int main ( int argc, char ** argv)	{
	if ( argc == 1) return 1;
	
	// Size of vectors
	unsigned long long n = atoll ( argv[1]);
	unsigned long long n_b = n/sizeof(double);

	// Allocate memory for vectors
	double	* a = malloc ( n),
		* b = malloc ( n),
		res = 0.0;
			
	// Init vector values		
	fill_vector ( a, n_b);
	fill_vector ( b, n_b);
	
	
	// Doing a dotprod
	for ( int i = 0; i < 10000; i++)
		res = dotprod ( a, b, n_b);


	// Free memory
	free ( a);
	free ( b);

	// Print dotprod result
	printf ("Res : %lf\n", res);
	
	return 0;
}

#+END_SRC

** Déroulement du processur d'optimisation

*** Etape initial : 00.dotprod

En premier lieu, on effecture une analyse du binaire obtenu avec uniquement les flags permettant à *MAQAO* de faire son analyse. On exploite alors
les informations mises à notre disposition afin d'améliorer les performances de notre programme dans l'ordre suivant : 


**** Index

On commence notre analyse par la page d'accueil du rapport. Sur cette page, on retrouve des informations préliminaires qui nous permettent de savoir
si un processus d'optimisation pourra nous permettre de gagner en performance ou non.

***** Global Metrics

     #+CAPTION: Rubrique 'Global Metrics' initial
     #+NAME: fig: initial_global_metrics
     #+ATTR_HTML: :width 300px
     [[./img/dotprod/00.dotprod/global.png]]

En observant les métriques globales du binaire analysé, on constate que celui-ci a été compilé sans flags d'optimisation ni de flags de spécification d'architecture.
De plus, on voit que d'une part, nos accès mémoire sont efficaces à 75% (la valeur est bonne mais pourrait être amélioré) et des speed-up peuvent-être otbtenus si le
programme est vectorisé à la compilation. Les possibilités d'améliorations seront présentées ultérieurement dans la rubrique *LOOPS* contenant l'essentiel des améliorations
suggéré.

A cette étape, nous allons prendre en compte la suggestion des flags [O2, O3, Ofast], -march=target et -funroll-loops pour le prochain binaire à produire.
***** Experiment Summary

     #+CAPTION: Rubrique 'Experiment Summary' initial
     #+NAME: fig: initial_experiment_summary
     #+ATTR_HTML: :width 500px
     [[./img/dotprod/00.dotprod/summary.png]]

A l'étape initiale, cette section ne nous est pas d'une grande utilité si ce n'est nous indiqué la micro-architecture de la machine cible ainsi que les flags que *gcc* ajoute
à notre place. Notre que la section précédente nous indiquait que l'option -march était manquant alors que celle-ci nous indique que -march=x86-64 a été indiquée.

**** Application

La section Application et plus particulièrement Detailed Application Categorization nous indique la couverture des différentes partie de notre code (code utilisateur, noyau, librairie externe, maths, etc ...)
Elle nous permet d'avoir une première évaluation de la portion de code réellement optimisable (généralement Binary et Math) via les suggestions d'optimisation du module *CQA*

     #+CAPTION: Detailed Application Categorization
     #+NAME: fig: initial_application Categorization
     #+ATTR_HTML: :width 500px
     [[./img/dotprod/00.dotprod/application.png]]

Dans le cas du dotprod avec des vecteurs mis à 1, la totalité du programme s'exécute au niveau du code utilisateur.

**** LOOPS

Maintenant que nous savons que notre code est optimisable et que les speed-ups potentiels sont interessant, nous allons nous intéresser au boucles à améliorer
et pouvoir découvrir les amélirations possibles.

***** Loops index

On regarde tout d'abord un tableau récapitulatif les boucles que nous devrons optimiser et pour mieux guider nos améliration (fixer une echelle de priorité pour un code possedant
plusieurs boucles à optimiser), on affiche le temps d'exécution de chacun ainsi que les speed-ups sur les types d'améliorationsa faire, suivant que les résultats affichés par le
tableau global. On choisit donc d'afficher les speed-ups si FP vectorisé et Totalement vectorisé.

     #+CAPTION: Initial Loops Index
     #+NAME: fig: initial_loops_index
     #+ATTR_HTML: :width 500px
     [[./img/dotprod/00.dotprod/loops_index.png]]

On constate qu'une boucle à une couverture de 99% et on décide donc de commencer par celle-la. On affiche donc son rapport *CQA*

**** Rapport *CQA*

Le rapport CQA se présente comme le montre la figure suivante :

     #+CAPTION: Rapport CQA de la boucle Loop_0
     #+NAME: fig: cqa_loop_0
     #+ATTR_HTML: :width 500px
     [[./img/dotprod/00.dotprod/cqa_main.png]]

On peut voir le code source de la boucle sur la gauche et les améliorations a effectuer dessus sur la droite. Nous allons réaliser chacune des
modificatoins demandée lorsque cela est possible afin de pouvoir constater dans une analyse ultérieur si notre programme est optimisé.

***** Gain : Code clean check

Un motif de perte de performance que nous avons pu observer sur la totalité des programmes analysés (écrits en C/C++) est la présence
d'instructions scalaires sur entier généralement causées par le calcul d'adressage. Nous decidons donc de ne plus utiliser l'opérateur []
au profit du déréférencement de pointeur ( a[i] devient *(a+i)). 

     #+CAPTION: Gain - Code clean check
     #+NAME: fig: initial_clean_check
     #+ATTR_HTML: :width 500px
     [[./img/dotprod/00.dotprod/code_clean_check.png]]

***** Gain : Vectorization

En plus de 
     #+CAPTION: Gain - Vectorization
     #+NAME: fig: initial_vecto_gain
     #+ATTR_HTML: :width 500px
     [[./img/dotprod/00.dotprod/vectorization.png]]
     
***** Potential : FMA

     #+CAPTION: Potential - FMA
     #+NAME: fig: initial_fma
     #+ATTR_HTML: :width 500px
     [[./img/dotprod/00.dotprod/fma.png]]

***** Gain : Unroll opportunity

     #+CAPTION: Gain - Unroll opportunity
     #+NAME: fig: initial_unroll
     #+ATTR_HTML: :width 500px
     [[./img/dotprod/00.dotprod/unroll_opportunity.png]]


*** Etape 2 : 

*** 

** Version finale optimisée

*** Makefile

#+BEGIN_SRC make
all: 03.dotprod

03.dotprod:
	gcc -Wall -g -fno-omit-frame-pointer -Ofast -march=native -funroll-loops -floop-unroll-and-jam -ftree-vectorize -fassociative-math -march=core-avx2 -o $@ $@.c
	
#+END_SRC

*** *dotprod.c*

#+BEGIN_SRC c
double dotprod(double *restrict a, double *restrict b, unsigned long long n)	{
	double d = 0.0;
	for ( unsigned long long i = 0; i < n; i++)	{
		d += ( *(a+i) * *(b+i) );
	}
	return d;	
}

void fill_vector (double *restrict vect, unsigned long long n)	{
	for (unsigned long long i = 0; i < n; i+=4)	{
		*(vect+i) = 1;
		*(vect+i+1) = 1;
		*(vect+i+2) = 1;
		*(vect+i+3) = 1;
	}
}

int main ( int argc, char ** argv)	{
	if ( argc == 1) return 1;
	
	// Size of vectors
	unsigned long long n = atoll ( argv[1]);
	unsigned long long n_b = n/sizeof(double);

	printf ("%llu\n", n);

	// Allocate memory for vectors
	double	* p_a = NULL,
		* p_b = NULL;
	int ret = 0;
	ret +=posix_memalign ((void **)  &p_a, 32, n);
	ret += posix_memalign ((void **) &p_b, 32, n);
	if ( ret) return 2;		
	double	* a = __builtin_assume_aligned(p_a, 32),
		* b = __builtin_assume_aligned(p_b, 32),
		res = 0.0;
			
	// Init vector values		
	fill_vector ( a, n_b);
	fill_vector ( b, n_b);
	
	
	// Doing a dotprod
	for ( int i = 0; i < 10000; i++)
		res = dotprod ( a, b, n_b);


	// Free memory
	free ( a);
	free ( b);

	// Print dotprod result
	printf ("Res : %lf\n", res);
	
	return 0;
}
#+END_SRC

*** Obersations

**** Informations non-exploitées

     #+CAPTION: Useless0
     #+NAME: fig: useless0
     #+ATTR_HTML: :width 500px
     [[./img/dotprod/00.dotprod/useless0.png]]

     #+CAPTION: Useless1
     #+NAME: fig: useless1
     #+ATTR_HTML: :width 500px
     [[./img/dotprod/00.dotprod/useless1.png]]

*  Mini-Applications

** HACC
** miniqmc
** NPB3.2.1-MZ

*  Suggestions pour MAQAO

*  Conclusion

** Optimisation grave a MAQAO

** Perspectives 

*  Bibliographie

1) http://www.maqao.org/
2) http://www.maqao.org/release/MAQAO_QuickReferenceSheet_V9.pdf
3) http://www.maqao.org/release/MAQAO.Tutorial.ONEVIEW.pdf
4) https://fr.wikipedia.org/wiki/Streaming_SIMD_Extensions
5) https://fr.wikipedia.org/wiki/Advanced_Vector_Extensions 
6) https://gcc.gnu.org/
7) https://gcc.gnu.org/onlinedocs/gcc-7.5.0/gcc/
8) https://gcc.gnu.org/onlinedocs/gcc-7.5.0/gcc/Option-Summary.html#Option-Summary
9) https://gcc.gnu.org/onlinedocs/gcc-7.5.0/gcc/Optimize-Options.html#Optimize-Options
10) https://www.nas.nasa.gov/assets/npb/NPB3.4.1-MZ.tar.gz
11) https://asc.llnl.gov/sites/asc/files/2020-09/haccmk.zip
12) https://github.com/QMCPACK/miniqmc
13) https://github.com/QMCPACK/miniqmc.git
