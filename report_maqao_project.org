#+TITLE: MAQAO REPORT
#+AUTHOR: Akli HAMITOUCHE - Amar HENNI - Amayas OUAKED - Imane KHELOUAT - Salem Aghiles BRAI

*  Introduction

** Présentation de l'outil MAQAO

C’est un outil composé de trois principaux modules (LProf, CQA, ONE View), qui permet d’analyser et optimiser les performances de programmes HPC, il est indépendant du langage utilisé et il ne nécessite pas de recompilation grâce à sa capacité à fonctionner au niveau binaire, il est compatibles sur plusieurs architectures (intel  AMD Xeon Phi) .
Il a pour objectif de guider les programmeurs à réaliser des applications optimisées en leur fournissant des rapports et des conseils détaillés tout au long du processus de développement.


** SIMD/Vectorisation

La vectorisation  est un processus de conversion  qui exécute des instructions SSE & AVX qui sont des extensions de l’architecture du jeu d’instructions SIMD des microprocesseurs x86, ces instructions sont utilisées de façon scalaire ou vectorielle et permettent de lancer simultanément une mêmes instructions sur plusieurs données afin de produire les résultats attendus avec un coût d'exécution minimale.

** Flags d'optimisation des compilateurs

|-------------------------+-----------+-------------------------------------------------------------------------------------------------|
| Flags                   | Valeurs   | Description                                                                                     |
|-------------------------+-----------+-------------------------------------------------------------------------------------------------|
| -g                      |           | produit les informations de debug dans le format de l'OS                                        |
|                         |           | permet d'avoir le lien entre le binaire et le source                                            |
| -fnp-omit-frame-pointer |           | permet d'avoir les callchains avec les options par défaut du profiler                           |
| -O2                     |           | produit un binaire légèrement optimisé                                                          |
| -O3                     |           | produit un binaire optimisé                                                                     |
| -Ofast                  |           | produit un binaire fortement optimisé                                                           |
| -funroll-loops          |           | force le déroulage des boucles                                                                  |
| -fassociative-math      |           | autorise la réassociatopn d'opérandes dans une série d'opération à virgule flottante            |
| -ftree-vectorize        |           | effectue la vectorisation de boucle sur les arbres ? : activé par défaut avec -O3               |
| -floop-unroll-and-jam   |           | non trouvée dans le manuel de GCC                                                               |
| -march=                 | native    | indique au compilateur de produire un binaire qui correspond au processeur d'exécution du code  |
|                         | core-avx2 |                                                                                                 |
|                         | x86-64    |                                                                                                 |
| -mtune=                 | native    | génère un code optimisé pour l'architecture cible tout en garantissant une retro-coçmpatibilité |
| -finline-functions      |           | inline toutes les fonctions simples                                                             |
| -flto                   |           | exécute l'optimiseur de temps de liaison                                                        |
|                         |           |                                                                                                 |
|-------------------------+-----------+-------------------------------------------------------------------------------------------------|


*  ABC-MAQAO sur un cas simple : *dotprod*

Afin de réaliser ce projet, une étape clé était de comprendre et d'apprendre à utiliser *MAQAO*. Pour cela, nous avons cherché à optimiser un
benchmark deja vu en cours : le *dotprod*. L'idée était de faire le travail d'optimisation un maximum de fois depuis la version de base afin 
d'identifier les informations récurrentes et exploitable qui nous étaient produites. Une fois ces sections identifiées, une chaine de production
d'un binaire (processus d'optimisation) a été mise en place et expliqué dans cette section.

Les résultats obtenus lors de cette analyse peuvent être retrouvés sur ce dépôt : [[Dépot contenant les RUNS et les sources du dotprod][https://github.com/m4ssi/Dotprod]]

** Chaine de production d'un binaire : 

La chaine de production mise en oeuvre, schématisée par la figure 1, se déroule telle que :

1) Compilation sans options de compilation
2) Analyse du binaire obtenu 
3) Recompilation du programme avec les options suggérés et avec O2, O3 ou Ofast (généralement Ofast - passage en 7)
4) Analyse des trois binaire obtenu
5) Si les suggestions faites sont differentes pour les trois : retour en 3
6) Sinon : choix du meilleur flags (compromis entre le temps d'exécution et taille du binaire) puis 7
7) Application des recommandations et analyse jusqu'a trouver une limite

   #+CAPTION: Processur iteratif d'optimisation à l'aide de MAQAO
   #+NAME: fig: optimization_process
   #+ATTR_HTML: :width 600px
   [[./img/inter_process.png]]

** Code source

*** Makefile

Comme on peut le voir sur le Makefile suivant, notre programme est compilé sans aucune optimisation
afin de commencer notre analyse depuis le début.

#+BEGIN_SRC make
all: 00.dotprod

00.dotprod:
	gcc -Wall -g -fno-omit-frame-pointer -O0 -o $@ $@.c
	
#+END_SRC

*** *dotprod.c*

Une particularité du dotprod ci-après présenté est qu'il nous permet de fixer une taille de vecteur en Bytes
et de boucler sur la fonciton principale afin de pouvoir jouer sur le temps d'exécution de notre programme d'une part
et ainsi mieux voir la performance gagné.

#+BEGIN_SRC c
double dotprod(double *restrict a, double *restrict b, unsigned long long n)	{
	double d = 0.0;
	for ( unsigned long long i = 0; i < n; i++)
		d += a[i] * b[i];
	return d;	
}

void fill_vector (double *restrict vect, unsigned long long n)	{
	for (unsigned long long i = 0; i < n; i++)
		vect[i] = 1;
}

int main ( int argc, char ** argv)	{
	if ( argc == 1) return 1;
	
	// Size of vectors
	unsigned long long n = atoll ( argv[1]);
	unsigned long long n_b = n/sizeof(double);

	// Allocate memory for vectors
	double	* a = malloc ( n),
		* b = malloc ( n),
		res = 0.0;
			
	// Init vector values		
	fill_vector ( a, n_b);
	fill_vector ( b, n_b);
	
	
	// Doing a dotprod
	for ( int i = 0; i < 10000; i++)
		res = dotprod ( a, b, n_b);


	// Free memory
	free ( a);
	free ( b);

	// Print dotprod result
	printf ("Res : %lf\n", res);
	
	return 0;
}

#+END_SRC

** Déroulement du processur d'optimisation

*** Etape initial : 00.dotprod

En premier lieu, on effecture une analyse du binaire obtenu avec uniquement les flags permettant à *MAQAO* de faire son analyse. On exploite alors
les informations mises à notre disposition afin d'améliorer les performances de notre programme dans l'ordre suivant : 


Il est important de préciser que notre programme ne possède que deux boucles à optimiser et que les améliorations à faire sur la 2e boucle sont les mêmes que sur la première.

**** Index

On commence notre analyse par la page d'accueil du rapport. Sur cette page, on retrouve des informations préliminaires qui nous permettent de savoir
si un processus d'optimisation pourra nous permettre de gagner en performance ou non.

***** Global Metrics

     #+CAPTION: Rubrique 'Global Metrics' initial
     #+NAME: fig: initial_global_metrics
     #+ATTR_HTML: :width 300px
     [[./img/dotprod/00.dotprod/global.png]]

En observant les métriques globales du binaire analysé, on constate que celui-ci a été compilé sans flags d'optimisation ni de flags de spécification d'architecture.
De plus, on voit que d'une part, nos accès mémoire sont efficaces à 75% (la valeur est bonne mais pourrait être amélioré) et des speed-up peuvent-être otbtenus si le
programme est vectorisé à la compilation. Les possibilités d'améliorations seront présentées ultérieurement dans la rubrique *LOOPS* contenant l'essentiel des améliorations
suggéré.

A cette étape, nous allons prendre en compte la suggestion des flags [O2, O3, Ofast], -march=target et -funroll-loops pour le prochain binaire à produire.
***** Experiment Summary

     #+CAPTION: Rubrique 'Experiment Summary' initial
     #+NAME: fig: initial_experiment_summary
     #+ATTR_HTML: :width 500px
     [[./img/dotprod/00.dotprod/summary.png]]

A l'étape initiale, cette section ne nous est pas d'une grande utilité si ce n'est nous indiqué la micro-architecture de la machine cible ainsi que les flags que *gcc* ajoute
à notre place. Notre que la section précédente nous indiquait que l'option -march était manquant alors que celle-ci nous indique que -march=x86-64 a été indiquée.

**** Application

La section Application et plus particulièrement Detailed Application Categorization nous indique la couverture des différentes partie de notre code (code utilisateur, noyau, librairie externe, maths, etc ...)
Elle nous permet d'avoir une première évaluation de la portion de code réellement optimisable (généralement Binary et Math) via les suggestions d'optimisation du module *CQA*

     #+CAPTION: Detailed Application Categorization
     #+NAME: fig: initial_application Categorization
     #+ATTR_HTML: :width 500px
     [[./img/dotprod/00.dotprod/application.png]]

Dans le cas du dotprod avec des vecteurs mis à 1, la totalité du programme s'exécute au niveau du code utilisateur.

**** LOOPS

Maintenant que nous savons que notre code est optimisable et que les speed-ups potentiels sont interessant, nous allons nous intéresser au boucles à améliorer
et pouvoir découvrir les amélirations possibles.

***** Loops index

On regarde tout d'abord un tableau récapitulatif les boucles que nous devrons optimiser et pour mieux guider nos améliration (fixer une echelle de priorité pour un code possedant
plusieurs boucles à optimiser), on affiche le temps d'exécution de chacun ainsi que les speed-ups sur les types d'améliorationsa faire, suivant que les résultats affichés par le
tableau global. On choisit donc d'afficher les speed-ups si FP vectorisé et Totalement vectorisé.

     #+CAPTION: Initial Loops Index
     #+NAME: fig: initial_loops_index
     #+ATTR_HTML: :width 500px
     [[./img/dotprod/00.dotprod/loops_index.png]]

On constate qu'une boucle à une couverture de 99% et on décide donc de commencer par celle-la. On affiche donc son rapport *CQA*

**** Rapport *CQA*

Le rapport CQA se présente comme le montre la figure suivante :

     #+CAPTION: Rapport CQA de la boucle Loop_0
     #+NAME: fig: cqa_loop_0
     #+ATTR_HTML: :width 500px
     [[./img/dotprod/00.dotprod/cqa_main.png]]

On peut voir le code source de la boucle sur la gauche et les améliorations a effectuer dessus sur la droite. Nous allons réaliser chacune des
modificatoins demandée lorsque cela est possible afin de pouvoir constater dans une analyse ultérieur si notre programme est optimisé.

***** Gain : Code clean check

Un motif de perte de performance que nous avons pu observer sur la totalité des programmes analysés (écrits en C/C++) est la présence
d'instructions scalaires sur entier généralement causées par le calcul d'adressage. Nous decidons donc de ne plus utiliser l'opérateur []
au profit du déréférencement de pointeur ( a[i] devient *(a+i)). 

     #+CAPTION: Gain - Code clean check
     #+NAME: fig: initial_clean_check
     #+ATTR_HTML: :width 500px
     [[./img/dotprod/00.dotprod/code_clean_check.png]]

***** Gain : Vectorization

En plus de nous indiquer la points de perte de performance, il nous est aussi proposé d'améliorer notre programme en recourant à la vectorisation.
Cette section se compose d'un constat sur le taux de vectorisaton (de pas du tout vectorisé à totalement vectorisé), une explication sur la vectorisatoin
et les instructions utilisées ainsi que le travail à faire. Nous prenons donc en compte pour notre prochaine compilation les flags *ftree-vectorize* et *fassociative-math*,
bien que présente dans les options O3 et Ofast.
     #+CAPTION: Gain - Vectorization
     #+NAME: fig: initial_vecto_gain
     #+ATTR_HTML: :width 500px
     [[./img/dotprod/00.dotprod/vectorization.png]]

Notons pour cette section, l'information sur les dépendances inter-iterations ne nous est d'aucune utilisé et n'est donc pas exploitable.
     
***** Potential : FMA

Une autre force de MAQAO est de détecter la présence d'aditions/soustractoins et de multiplications et nous invite donc à changer la synthaxe de
notre operation d'accumulation et avoir un gain de performance. Cette section nous permet également de savoir a quel point le code est vectorisé : 
plus il y aura d'operation FMA et plus les registres SSE/AVX sont utilisés.

Pour la suite, on décide donc de remplacer les operations a + b * c par a + (b + c) et d'ajouter l'option *-march=core-avx2*.
     #+CAPTION: Potential - FMA
     #+NAME: fig: initial_fma
     #+ATTR_HTML: :width 500px
     [[./img/dotprod/00.dotprod/fma.png]]

***** Hint : Unroll opportunity

Un dernier point important que nous cherchons systématiquement a voir est l'opportunité de déroulage de boucles. Ceci peut se faire en conjuguant un déroulage
manuel et l'ajout des options *-funroll-loops* et/ou *-floop-unroll-and-jam*.

     #+CAPTION: Gain - Unroll opportunity
     #+NAME: fig: initial_unroll
     #+ATTR_HTML: :width 500px
     [[./img/dotprod/00.dotprod/unroll_opportunity.png]]



*** Etape 2 : 



*** 

** Version finale optimisée

*** Makefile

#+BEGIN_SRC make
all: 03.dotprod

03.dotprod:
	gcc -Wall -g -fno-omit-frame-pointer -Ofast -march=native -funroll-loops -floop-unroll-and-jam -ftree-vectorize -fassociative-math -march=core-avx2 -o $@ $@.c
	
#+END_SRC

*** *dotprod.c*

#+BEGIN_SRC c
double dotprod(double *restrict a, double *restrict b, unsigned long long n)	{
	double d = 0.0;
	for ( unsigned long long i = 0; i < n; i++)	{
		d += ( *(a+i) * *(b+i) );
	}
	return d;	
}

void fill_vector (double *restrict vect, unsigned long long n)	{
	for (unsigned long long i = 0; i < n; i+=4)	{
		*(vect+i) = 1;
		*(vect+i+1) = 1;
		*(vect+i+2) = 1;
		*(vect+i+3) = 1;
	}
}

int main ( int argc, char ** argv)	{
	if ( argc == 1) return 1;
	
	// Size of vectors
	unsigned long long n = atoll ( argv[1]);
	unsigned long long n_b = n/sizeof(double);

	printf ("%llu\n", n);

	// Allocate memory for vectors
	double	* p_a = NULL,
		* p_b = NULL;
	int ret = 0;
	ret +=posix_memalign ((void **)  &p_a, 32, n);
	ret += posix_memalign ((void **) &p_b, 32, n);
	if ( ret) return 2;		
	double	* a = __builtin_assume_aligned(p_a, 32),
		* b = __builtin_assume_aligned(p_b, 32),
		res = 0.0;
			
	// Init vector values		
	fill_vector ( a, n_b);
	fill_vector ( b, n_b);
	
	
	// Doing a dotprod
	for ( int i = 0; i < 10000; i++)
		res = dotprod ( a, b, n_b);


	// Free memory
	free ( a);
	free ( b);

	// Print dotprod result
	printf ("Res : %lf\n", res);
	
	return 0;
}
#+END_SRC

*** Obersations

**** Informations non-exploitées

     #+CAPTION: Useless0
     #+NAME: fig: useless0
     #+ATTR_HTML: :width 500px
     [[./img/dotprod/00.dotprod/useless0.png]]

     #+CAPTION: Useless1
     #+NAME: fig: useless1
     #+ATTR_HTML: :width 500px
     [[./img/dotprod/00.dotprod/useless1.png]]

*  Mini-Applications

** HACC
** miniqmc
** NPB3.2.1-MZ

*  Suggestions pour MAQAO

*  Conclusion

** Optimisation grave a MAQAO

** Perspectives 

*  Bibliographie

1) http://www.maqao.org/
2) http://www.maqao.org/release/MAQAO_QuickReferenceSheet_V9.pdf
3) http://www.maqao.org/release/MAQAO.Tutorial.ONEVIEW.pdf
4) https://fr.wikipedia.org/wiki/Streaming_SIMD_Extensions
5) https://fr.wikipedia.org/wiki/Advanced_Vector_Extensions 
6) https://gcc.gnu.org/
7) https://gcc.gnu.org/onlinedocs/gcc-7.5.0/gcc/
8) https://gcc.gnu.org/onlinedocs/gcc-7.5.0/gcc/Option-Summary.html#Option-Summary
9) https://gcc.gnu.org/onlinedocs/gcc-7.5.0/gcc/Optimize-Options.html#Optimize-Options
10) https://www.nas.nasa.gov/assets/npb/NPB3.4.1-MZ.tar.gz
11) https://asc.llnl.gov/sites/asc/files/2020-09/haccmk.zip
12) https://github.com/QMCPACK/miniqmc
13) https://github.com/QMCPACK/miniqmc.git
